<details>
  <summary>Сентябрь 2025 (9 штук)</summary>

<details>
  <summary>Яндекс</summary>

пт
# [1] Задача 
 ```sql
with tmp as (select user_id, order_id,
row_number() over (partition by user_id order by order_timestamp) as rn
from taxi)
select user_id, order_id from tmp
where rn = 1

 ```
 # [2] Задача 
 ```sql
select t1.car_number
from sandbox.zvereva_taxi_orders t1 join sandbox.zvereva_taxi_orders t2 on t1.car_number = t2.car_number
and t1.endd>t2.start and t1.start<t2.endd

 ```
 # [3] Задача 
 ```python
'''1 вариант:'''

from collections import Counter

def find_mode (arr: list):
  arr = Counter(arr)
  return max (counter, key = counter.get)

'''2 вариант'''

def find_mode (arr: list):
  moda_count = 0
  k = 0
  arr = sorted(arr)
  for i in range (len(arr)-1):
    if arr[i] == arr[i+1]:
      k += 1
    else:
      if k > moda_count:
        moda_count = k
        moda = arr[i]
      k = 0
  return moda


 ```
 # [4] Задача 
 ```python

def func(d:dict):
  d_new = {}
  arr_keys = list(d.keys())
  arr_values = list(d.values())
  for i in range(len(d)):
    d_new.update ({ arr_values[i] : arr_keys[i]})

  return d_new

 ```

</details>

<details>
  <summary>ЭР-Телеком</summary>

сб
 # [1] Задача 
[1, 2, 3, 1, 2, 3]

 # [2] Задача 
arr = [x*2 for x in arr]

 # [3] Задача 

 1 
 2
 3 


 1

# [4] Задача 

Каждому человеку даем 2 стаканчика, он их пробует всплепую, очередность стаканчиков определяется рандомом. Затем собираем выборку из большого числа наблюдений. Считаем кол-во голосов за каждый вид колы, а затем с помощью стат теста проверяем, значимы ли статистически результаты. Стат тест берем биномиальный, потому что он подходит для бинарных выводов

(задача на двойное слепое тестирование)


</details>



<details>
  <summary>Т-банк</summary>

вс
# [1] Задача 

 ```sql
select t1.id, t1.department_id
from employee t1
join employee t2
on t1.department_id = t2.department_id 
and t1.chief_flg = False
and t2.chief_flg = True
and t1.birth_dt < t2.birth_dt
group by t1.id, t1.department_id
 ```

 # [2] Задача 

 ```sql
with tmp as (
  select transaction_id, customer_id, amount_rur, transaction_dttm,
  row_number() over (partition by customer_id order by transaction_dttm) as rn,
  sum(amount_rur) over (partition by customer_id) as sm
  from transactions
  where success_flg = True
)
select  transaction_id, customer_id, amount_rur, transaction_dttm
from tmp
where rn = 1 and sm > 1000000
 ```

  # [3] Задача 

 ```sql
with tmp as (
  select transaction_id, customer_id, amount_rur,
  lag(amount_rur) over (partition by customer_id order by transaction_dttm) as lg,
  lead(amount_rur) over (partition by customer_id order by transaction_dttm) as ld
)
select transaction_id, customer_id, amount_rur
from tmp
where amount_rur > lg and amount_rur < ld
 ```

# [4] Задача 

 ```sql
with tmp as (select client_id, sum(amount) as sm
from transaction t join account a on t.account_id = a.id
where transaction_date > current_date - interval '1 month'
and type = 'покупка'
group by client_id)
select distinct name
from client c join account a2 on c.id = a2.client_id
where close_dt is null
and c.id in (select client_id from tmp where sm < 5000)
and open_dt < current_date - interval '1 year'
 ```

# [5] Задача 

 ```sql
SELECT 
    c1.id,
    c1.points,
    COUNT(DISTINCT c2.points) + 1 as position
FROM sandbox.zvereva_competition c1
LEFT JOIN sandbox.zvereva_competition c2 ON c2.points > c1.points
GROUP BY c1.id, c1.points
ORDER BY c1.points DESC;
 ```
</details>


<details>
  <summary>Лига цифровой экономики</summary>

пн

# [1] Задача 

t1: 3   t2: 4
INNER JOIN
min: 0
max: 12

LEFT JOIN
min: 3
max: 12

RIGHT JOIN
min: 4
max: 12

FULL JOIN
min: 4
max: 12

CROSS JOIN
min: 12
max: 12


 # [2] Задача 

 ```sql
SELECT value, count(value) as cnt
from T
group by value
having count(value) > 1
 ```

# [3] Задача 

 ```sql
tmp as (SELECT empl_fio, empl_dep, amount,
row_number() over (partition by empl_dep order by amount desc) as rn
from salary
where extract(month from value_day) = 4
and extract(year from value_day) = 2023)
select empl_fio, empl_dep, amount from tmp
where rn = 2
 ```

 # [4] Задача 

 ```sql
with tmp as (select empl_fio, empl_dep, amount as may_amount,
dense_rank() over (order by amount) as rank
from salary
where extract(month from value_day) = 5
and extract(year from value_day) = 2023),

apr as (
  select empl_fio, empl_dep, amount as april_amount, value_day
  from salary
  where extract(month from value_day) = 4
and extract(year from value_day) = 2023) 


select t.empl_fio, t.empl_dep, (may_amount - april_amount) as diff, may_amount
from tmp t join apr a on t.empl_fio = a.empl_fio and t.empl_dep = a.empl_dep 
where rank <= 3
 ```
</details>

<details>
  <summary>Wildberries</summary>

вт

 # [1] Задача 

 ```sql
select t1.id, t1.name, t1.salary, t2.salary
from employee t1 join employee t2 on t1.manager_id = t2.id and t1.salary > t2.salary

 ```

 # [2] Задача 

 ```sql
with tmp as (select id, name, salary, departmentID,
dense_rank() over (partition by departmentID order by salary desc) as rk
from employee)
select name
from tmp
where rk <= 3
 ```
# [3] Задача 

 ```python
'''Напишите функцию, которая принимает на вход список hours (содержащий N элементов) и целое число target.
Функция должна возвращать количество сотрудников, отработавших не меньше target часов'''

def func(hours, target):
  cnt = 0
  for i in range(len(hours)):
    if hours[i] >= target:
      cnt += 1
  return cnt
 ```

 # [3] Задача 

 ```python
df['DepositionSum'].mean()
df['WithdrawalSum'].mean()

df.groupby('Day').agg({'DepositionSum': 'mean',
                       'WithdrawalSum': 'mean'}).mean()

df.groupby('UserId').agg({'DepositionSum': 'mean',
                       'WithdrawalSum': 'mean'}).mean()

df['DepositionSum'].sum() - df['WithdrawalSum'].sum()

'''Сегментация: k-means, по сумме депозита, по частоте'''

 ```

</details>

<details>
  <summary>Бетсити</summary>

ср

 # [1] Задача 

 d

 # [2] Задача 

 bc

b. TRUNCATE TABLE my_table - удаляет все строки, быстрее, нельзя откатить
c. DELETE FROM my_table - удаляет все строки, можно использовать с WHERE, можно откатить
a. DROP TABLE my_table - удаляет саму таблицу
d. DELETE my_table - неверный синтаксис (требуется FROM)

 # [3] Задача 

(4500*20+1500*50+2500*30)/100
2400

 # [4] Задача 

Доходы с контрольной группы: 1500
Доходы с целевой группы: 18000
Расходы на рассылку контроль: 500
Расходы на рассылку целевая: 4500

Прибыль со старой конверсией:
10000*0.03*50 = 15000

Прибыль с новой конверсией:
10000*0.04*50 - 5000 = 15000

Итого: эффекта нет


# [5] Задача 

 ```sql
select t1.name, t1.salary, t2.name, t2.salary, t3.name
from employee t1 join employee t2 on t1.chief_id = t2.id 
join department t3 on t1.department_id = t3.id
where t2.salary / t1.salary between 1.5 and 2
 ```


# [6] Задача 

 ```sql
select extract (month from sale_dttm) as month, extract (year from sale_dttm) as year,
percentile_cont(0.5) within group (order by price * (1-discount/100))
from tmp
group by year, month
order by year, month
 ```



</details>


<details>
  <summary>Wildberries</summary>

чт

 # [1] Задача 

 ```sql
with tmp as (select courier_id, pickup_point,
avg(delivery_time) as ag
from orders
where delivery_time <= 120
group by courier_id, pickup_point),

tmp_2 as (select pickup_point, courier_id, 
row_number() over (partition by pickup_point order by ag) as rn
from tmp)

select pickup_point, courier_id from tmp_2
where rn = 1
 ```

# [2] Задача 

 ```sql
with tmp as (select order_date, courier_id, avg(delivery_time) as ag_days
from deliveries
group by order_date, courier_id)

select order_date, courier_id,
avg (ag_days) over (partition by courier_id order by order_date rows between 6 preceding and current row)
from tmp
 ```

# [3] Задача 

 ```python
 import pandas as pd
 df = pd.read_csv('Таблица')

 df.groupby('courier_id').agg({'delivery_time':'mean', 'distance':'mean'})

df['efficiency'] = df['distance']/df['delivery_time']
df.groupby(['start_location', 'end_location']).agg({'efficiency': 'mean'})

df.groupby('courier_id')['efficiency'].mean().sort_values(ascending=False)
 ```

</details>

<details>
  <summary>HeadHunter</summary>

пт

# [1] Задача 

 ```sql
with tmp as (
  select product_id, extract(year from sale_date) as yr, extract(month from sale_date) as mh,
sum(amount) over (partition by product_id, extract(year from sale_date), extract(month from sale_date)) as sm
from sales),
tmp_2 as (
  select product_id, yr, mh, sm,
  lag(sm) over (partition by product_id order by yr, mh) as lg
  from tmp
)
select product_id, yr, mh, coalesce((sm-lg)/nullif(lg,0),0)*100 as final
from tmp_2
order by yr, mh
 ```

# [2] Задача 

 ```python
def func(x):
  cnt = 0
  if not isinstance (x,int):
    return 'Не целое число'
  if x < 0:
    return 'Отрицательное число не может быть составным'
  elif x == 1 or x == 0:
    return 'Ни простое, ни составное'
  else:
    for i in range (2, x+1):
      if x%i == 0:
        cnt += 1
    if cnt == 1:
      return 'Простое'
    else:
      return 'Составное'
 ```

 # [3] Задача 

 ```python
def func(n):
  nums = [0, 1]
  for i in range(2,n+1):
    nums.append(nums[i-1] + nums[i - 2])
  return nums[n]
 ```
 # [4] Задача 

Чему равна вероятность выпадения двух шестерок на двух игральных костях, если сумма выпавших очков четна

С - сумма выпавших очков четна
P(C) = 1/2
так как
18*2 - всего случаев
четных - 18

Р(А) - вероятность выпадения двух шестерок
1/36 

Р(С|A) - вероятность выпасть четному кол-ву очков, если выпали 2 шестерки = 1

Р(А|C) = Р(В|A)*P(A)/P(C) = 1/36 * 2/1 = 1/18

# [5] Задача 

Кидаем 5 раз монетку. Какая вероятность того, что Орел выпадет 3 раза из 5 в любом порядке?

Кол-во благоприятных исходов: С(3,5) = 5!/2!*3! = 10
Кол-во всех исходов: 2*2*2*2*2 = 32
Ответ: 10/32 = 5/16

</details>

<details>
  <summary>CloudPayments</summary>

сб
 # [1] Задача 

 ```sql
select distinct student_id from students 
where student_id not in(
  select student_id from students s join marks m on s.id = m.student_id 
  where mark in (1,2,3)
)
 ```

 # [2] Задача 

 ```sql

with tmp as (select m.id, 
sum(amount) over (partition by m.id) as sm,
row_number() over (partition by m.id order by date_trans desc) as rn
from merchant m inner join merch_transaction t on m.id = t.merch_id
where type = 'Успешно')
select id, sm from tmp
where rn = 1

 ```
 # [3] Задача 

 ```sql
select id, 
sum(amount) over (partition by m.id order by date_trans) as sm
from merchant m inner join merch_transaction t on m.id = t.merch_id
where type = 'Успешно'
 ```
 # [4] Задача 

 ```python
df_final = df_amounts.groupby('scopeid')['amount'].sum().sort_values(ascending = False).head(3)
df_final = df_final.reset_index()
df_final = df_final.merge(df_names, on = 'scopeid', how = 'left')
df_final[['scope_name', 'amount']]
 ```

</details>


</details>


<details>
  <summary>Ноябрь 2025 (2 штуки)</summary>

<details>
  <summary>Точка 2</summary>
  вс

 # [1] Задача 

- Объяснить, в чём принципиальная разница в результате между этими двумя запросами.

В ON - фильтрация выполняется во время соединения, то есть из второй таблицы не возьмутся строки с id>=5
В where - фильтрация происходит уже после соединения, то есть из всей готовой таблицы удалятся те строки, где b.id>=5 

- На небольшом примере данных (в том числе с значениями 2, 5, 10) показать, какие строки попадут в результат каждого запроса.

2 кот    
5 собака
10 мышь

2 кот
7 крыса
10 мышь

вариант 1 с where:
10 мышь мышь

вариант 2 с on:

2 кот null
5 собака null
10 мышь мышь

# [2] Задача 

 ```sql

-- Написать SQL-скрипт, который позволит однозначно ответить на вопрос: совпадают ли результаты этих двух выборок или нет

with diff as (select a.id, b.id
from a full outer join b on a.id = b.id or (a.id is Null and b.id is Null)
where a.id is distinct from b.id)
select 
case
when exists (select True from diff) then 'Отличия есть'
else 'Отличий нет'
end as result
 ```
# [3] Задача - Продуктовый кейс: отдел обзвона клиентов

В компании есть отдел, который обзванивает клиентов и продаёт им продукт. Руководству нужно понять, оставлять ли этот отдел в следующем году или закрывать.

Известно:

Оператор делает около 100 звонков в день.
Конверсия в подключение по результатам обзвона — 5%.
С одной продажи компания получает 3000 ₽ (считать это чистой маржой).
Зарплата сотрудника — порядка 70 000 ₽ в месяц + налоги (итого около 100 000 ₽ совокупных затрат).
Без обзвона есть «естественная» конверсия клиентов в подключение — 3%.
Нужно:

Предложить, какие метрики и расчёты нужно сделать, чтобы решить, выгоден ли отдел обзвона.
Показать, как учесть естественную конверсию (3%) и выделить именно дополнительный эффект от работы оператора.
Сравнить дополнительную выручку/маржу с затратами на отдел и сделать вывод, стоит ли его оставлять.


1) Если после обзвона конверсия 5, а естественная 3, то тогда эти +2% - полученная выгода

100 * 0.02 * 3000 = 6000 - это прибыль с одного сотрудника за день

за месяц с одного сотрудника прибыль: 6000 * 22 рабочих дня - 100000 = 32 000

2) Можно предложить метрику ROMI

(доп прибыль)/ затраты = 132000/100000 = 132% (> 100%, значит вложения окупаются)
Решение: оставлять отдел обзвона
 </details>

<details>
  <summary>Билайн</summary>
  пн


# [1] Задача  Сумма положительных и отрицательных значений

 ```sql
--Есть таблица values_table с единственным числовым полем v. В этом поле могут быть как положительные, так и отрицательные значения. Требуется написать SQL-запрос, который посчитает:

-- сумму всех положительных значений поля v;
-- сумму всех отрицательных значений поля v.

SELECT 
    SUM(CASE WHEN v > 0 THEN v ELSE 0 END) AS sum_posit,
    SUM(CASE WHEN v < 0 THEN v ELSE 0 END) AS sum_negat
FROM values_table;
 ```


# [2] Задача Группировка чисел по диапазонам

 ```sql

-- Используя ту же таблицу values_table(v), нужно сгруппировать все значения по диапазонам одинаковой ширины, например по 1000 единиц: от -2000 до -1000, от -1000 до 0, от 0 до 1000, от 1000 до 2000 и т.д. Требуется написать SQL-запрос, который:

-- относит каждое значение v к соответствующему диапазону;
-- считает количество значений в каждом диапазоне;
-- выводит только те диапазоны, в которых есть хотя бы одно значение.

with tmp as (select v,
case 
when v >= -2000 and v < -1000 then 'от -2000 до -1000'
when v >= -1000 and v < 0 then 'от -1000 до 0'
when v >= 0 and v < 1000 then 'от 0 до 1000'
when v >= 1000 and v <= 2000 then 'от 1000 до 2000'
end as group_range
from values_table)
select group_range,
count(v) as cnt_v
from tmp
where group_range is not null
group by group_range
 ```
</details>
</details>



<details>
  <summary>Декабрь 2025 (6 штук)</summary>

<details>
  <summary>Сбер</summary>
  вт

# [1] Задача

 ```sql
--Сколько клиентов видели рекламу не менее 2х раз

select id, count(id) as cnt
from events 
where event = 'SHOWN'
group by id
having count(id) >= 2
 ```

 # [2] Задача

 ```sql
--Сколько было показов и кликов
select
count(case when event = 'SHOWN' then 1 end) as shown,
count(case when event = 'STARTED' then 1 end) as started
from events

-- Конверсия клики/показы
with tmp as (select
count(case when event = 'SHOWN' then 1 end) as shown,
count(case when event = 'STARTED' then 1 end) as started
from events)
select round(started::float/shown,2)*100 as cr
from tmp

-- Сколько было сделано продаж в течение 4х дней после клика?

with tmp as (select id, s.ts as ts_sale, e.ts as ts_click
from sales s left join events e on s.id = e.id and e.event = 'STARTED' and s.ts > e.ts)
select count (distinct id)
from tmp
where datediff('dd', ts_click, ts_sale) <= 4 and ts_click is not null
 ```

 # [3] Кейс АБ

Проведен АБ тест - показаны 2 разных кредита разным группам людей.
Полученные результаты показывают отсутствие разницы между сtr.
Вы сомневаетесь в правильности выводов, поскольку это противоречит ранее проведенным исследованиям, которые проводили не вы.
С чем вы связываете отсутствие различия?

Что нужно проверить?
- корректность проведения аб теста (нет ли peeking prblem, srm, сколько держали аб и набралась ли достаточная выборка, корректно ли выбран стат критерий)
- было ли соблюдено правило случайного распределения пользователей, действительно ли пользователь оказался только в одной группе
- не было ли такого, что тестировали на разных каналах привлечения
- не проводился ли тест в праздники? или других отличные от будней дней?
- не было ли множественного тестирования
- возможно была выбрана некорректная метрика
- баги

 # [4] Кейс

 Ситуация: пришел на работу -> витрина пустая в БД. Что делать?

1) Посмотрю рабочие чаты и почту - вдруг DE уже предупредили о проблеме?
2) Пойду узнаю у ответственных за витрину - если это не моя ответственность
3) Если моя, то пойду проверять, что сломалось:
- проверю логи, алерты, чтобы понять, когда витрина упала
- проверю, когда были сделаны последние изменения
- проверю, все ли окей с источником данных
- если есть бэкап, то временно поднимаю витрину из бэкапа
- запускаю бэктил (перерасчет данных)
- иду к de

Какие вопросы важно задать?

Когда перестала работать? (по логам/мониторингу)
Что изменилось перед этим? (деплой, изменение данных, нагрузки)
Кто использует витрину? (чтобы оценить срочность)
Есть ли бэкап/ snapshot? (можно ли быстро восстановить)

</details>

<details>
  <summary>Сбер Здоровье</summary>

ср

# [1] Задача

 ```sql
-- Вывести разницу income в процентах по каждой стране YoY, сравнивая октябрь 2022 с откябрем 2023

with tmp as (select extract(year from s.date) as yr, country_name, sum(income) as sm
from country c  left join sales s on c.city = s.city and extract(month from s.date) = 10 and extract(year from s.date) in (2022,2023)
group by country_name, yr)
select country_name,
(sm - lag(sm) over (partition by country_name order by yr))/lag(sm) over (partition by country_name order by yr)*100 as perc
from tmp
where yr is not null
 ```

 # [2] Задача

 ```sql
-- Запрос retention-анализа

with first_actions as (select user_id, date_trunc('week', ts) as week, 
date_trunc ('week', min(ts) filter (where event_name = 'Install')) as f_install,
date_trunc ('week', min(ts) filter (where event_name = 'Consultation')) as f_consultation
from event_log
group by user_id, date_trunc('week', ts)),

retention as (
  select f_install, user_id,
  (f_consultation - f_install) / interval '1 week' as diff
  from first_actions
)

select f_install as "Неделя первой установки", 
avg(diff) AS "Количество недель между первой установкой и Consultation",
count(distinct user_id) AS "Количество уников в когорте",
count(distinct case when diff is not null then user_id) AS "Количество уников совершивших Consultation в эту неделю"
from retention
group by f_install
order by f_install
 ```
# [3] Задача

Что делает конструкция df['col'] = df['col'].map(lambda x: 1 if x=='test' else 0)?

к каждому значению в столбце применяется функция лямбда6 то есть если значение в столбце = test, то тогда пишется 1, если не test, то 0

Альтернатива: df = df.apply(lambda x: 1 if x['col']=='test' else 0, 1)?

если значение в столбце = test, то тогда возвращается 1, если нет, то 0 (а к строке, потому что стоит 1 в apply)
вернется не df, а series, то есть [1,0,0,1 и тд]

# [4] Задача
Что делает этот код?
sorted(zip([1230930093, 123630960960, 123960132511], ['Maxim A.', 'Alexander P.', 'Ilya R.']), key=lambda x: x[1], reverse=True)

zip - объединяет списки в кортеж
сортирует кортеж по именам (потому что 1 - индекс) и в обратном алфавитном порядке

# [5] Задача

 ```python
import pandas as pd
df = pd.read_csv('Название')

'''Для каждого магазина вывести общую сумму продаж'''

df['total'] = df['amount'] * df['price']
df.groupby('store')['total'].sum()

'''Для каждого магазина вывести среднюю цену товара'''
df.groupby('store')['price'].mean()

'''Для каждого магазина вывести количество уникальных товаров'''
df.groupby('store')['item'].nunique()

 ```
# [6] Задача

Представим интернет-магазин, в котором есть 2 канала продаж: web и mobile. Во всех каналах вырос средний чек. Что произошло с общим средним чеком?

Нельзя однозначно сказать, что стало с общим средним чеком - он мог как упасть, так и вырасти, так и не измениться. Все дело в парадоксе симпсона.

Приведу пример

Пусть люди покупают компьютеры и телефоны в магазинах А и Б

В магазине А:
Веб: 
телефоны: 15
компьютеры: 18
доля тех, кто купил телефоны: 0,45

Мобайл
телефоны: 18
компьютеры: 9
доля тех, кто купил телефоны: 0,67

В магазине Б:
Веб: 
телефоны: 9
компьютеры: 12
доля тех, кто купил телефоны: 0,43

Мобайл
телефоны: 27
компьютеры: 15
доля тех, кто купил телефоны: 0,64

Мы видим, что доля той категории покупателей, кто купил телефон выше и в магазине А, и в магазине Б 

Теперь объединим

Магазин А: (15+18)/(15+18+18+9) = 0,55
Магазин Б: (9+27)/(9+12+27+15) = 0,57

И вот тут парадокс Симпсона! При объединении категорий получили, что доля выше в магазине Б

# [7] Задача

Объясните, что такое ошибка первого рода (α) и второго рода (β) в контексте проверки гипотез.
Как они связаны с нулевой и альтернативной гипотезами?

ошибка первого рода - это вероятность отвергнуть нулевую гипотезу, при условии, что она верна (FPR)
в контексте проверки гипотез берут критерий значимости альфа - это и есть вероятность "ошибиться", то есть ложно отвергнуть нулевую гипотезу

ошибка второго рода - это вероятность не отклонить нулевую гипотезу, при условии, что она не верна (FNR)
также есть мощность теста (1 - бетта) - это вероятность правильно отклонить нулевую гипотезу когда h1 верна

</details>

<details>
  <summary>Medsi всякие теор вопросы</summary>
  чт

# [1] BI / SQL / Data Engineering

• Опиши полный процесс разработки дашборда: сбор требований, формализация
метрик, проверка наличия данных, создание витрин, подключение к Power BI,
публикация, документация

- сначала необходимо понять бизнес-задачу, цели, какие проблемы будет решать, собрать требования к дашборду
- затем создание прототипа, метрик
- подготовка и проверка данных, создание витрины
- подключение к powerbi
- создание дашборда
- публикация
- документация
- инструктаж

• Как устроена структура DAG в Airflow? Как формируются SQL-скрипты, где
хранятся, как выполняются?

- DAG в Airflow позволяют выполнять определенный скрипт по расписанию - например, заливать данные в витрину

DAG состоит из тасков(operators), которые могут быть sql-скриптами, python-запросами и тд
SQL-скрипты обычно хранятся отдельно в репозитории и выполняются через оператор

• Как работает импорт данных в Power BI: отличие Import Mode от DirectQuery?
В PowerBI используется схема звездочка, то есть связь один ко многим, поэтому можно работать с данными прямо в PowerBI. Можно импортировать из
разных источников - БД, файлы, эксель и тд. Import Mode - данные импортируются в PowerBI и расчеты происходят внутри повербиай. 
DirectQuery - повербиай отправляет запросы в БД, поэтому данные скорее всего актуальные 

• Как ты создаёшь витрину в ClickHouse и запускаешь её в автоматический
пересчёт через Airflow?
1) Я делаю скл-скрипт, который джойнит и фильтрует данных (через DBeaver) и формирую таблицы в dwh. 
2) Проверяю скрипт локально в дбивере
3) Загружаю скрипт в репозиторий или хранилище файлов
4) Далее пишу скрипт dag, где один из тасков выполняет sql-скрипт на clickhouse через clickhouseoperator
5) настраиваю расписание DAG, чтобы данные обновлялись
6) Проверяю выполнение и мониторю DAG через веб-интерфейс Airflow

# [2] A/B-тестирование

• Как формулируется гипотеза, как выбираются метрики (целевые и защитные)?

- гипотеза формулируется исходя из задачи бизнеса и возможно какого-то проведенного исследования, а возможно просто от желания протестировать новую фичу
- метрики выбираются исходя из того, что мы хотим проверить (конверсия, средний чек?), при этом метрика должна быть устоячива к шуму (низкодисперстной), но при этом и быть детектируемой за небольшой период времени (то есть не ltv). также метрика должна давать четкий ответ на вопрос - стало лучше/хуже (например, конверсия выросла - это хорошо), метрика должна отражать эффект от этой фичи (например, лучше проверить конверсию в нажатие кнопки от нового попапа, чем проверять конверсию в продажу от всего лендинга), также метрика должна быть такой, чтобы ее могли задетектить стат тесты, также метрика должна быть косвенно или напрямую связана с прибылью
гипотеза должна быть конкретной, направленной и измеряемой количественно

- защитные метрики должны отражать какие-то стороны продукта, которые мы не должны поломать новой фичей - например, конверсию в оплату или время проведенное на сайте. то есть эта метрика тоже должна быть четкая, умеренно чувствительная и иметь понятное бизнесовое значение (почему ее ломать - это критично?). защитные метрики должны отражать риски

• Как рассчитывается MDE, какое количество наблюдений нужно, сколько
должен идти тест?
- MDE рассчитываем, исходя из мощности теста, альфа, кол-во наблюдений, длительности теста - мы подставляем параметры и получаем определенный mde. если мы понимаем, что этот mde нам достигнуть почти нереально, то нужно менять что-то в параметрах - например, увеличивать выборку или срок теста

- также и с остальными - кол-вом наблюдений и сроком теста. мы можем заранее понять (посчитать юнит экономику), какой нам нужен mde, и уже отталкиваюсь от него считать срок и кол-во наблюдений

1) бизнес говорит mde
2) аналитик считает выборку
3) выборка определяет длительность теста
4) если длительность большая, меняем параметры

• Как выбирается статистический критерий (t-test, z-test, U-test, bootstrap)?
- выбирается в зависимости от метрики (конверсионная, числовая и так далее), то есть выбирается от распределения, объёма данных, дисперсии

• Как проектируется рандомизация без сплитовалки? Какие атрибуты
балансировать?
- используем хэш-функцию
нужно балансировать (гео, канал трафика, тип устройства, платформа, новая/повторная сессия, объём трафика)

• Как интерпретировать доверительный интервал?
- мы получаем определенное значение после эксперимента, далее смотрим доверительный интервал - с вероятностью (1 - альфа) наше истинное значение будет лежать в этом интервале при проведении множества экспериментов
мы можем получить стат значимый результат, но в доверительный интервал попадет значение, которое нам будет не особо полезно как бизнесу (маленькое), тогда мы задумаемся, а стоит ли вообще катить фичу - то етсь мы не полагаемся только на p value

• Как проводить мультивариантное тестирование и учитывать поправку
Бонферрони?

- если у нас несколько сравнений (множественное стравнение), то тогда мы можем поделить на кол-во гипотез, чтобы уменьшить ошибку первого рода


# [4] Юнит-экономика / Метрики

• Как формировать финансовую модель продукта?

финансовая модель продукта включает в себя:
- прогноз трафика, конверсий, то есть воронки
- юнит-экономику (cac, ltv, arpu, arppu, roi, cogs)
- модель выручки(подписка, комиссии, GMV - revenue) и затрат (прямые/косвенные/переменные/постоянные)
- P&L по месяцам (выручка, EBITDA)
- кэшфлоу (движение денег во времени)
- точку безубыточности

• Как распределять доходы/расходы по периодам?
если нет подписочной модели, то тогда какие в этом месяце доходы и расходы, то и относим в данный месяц
что касается косвенных расходов, то есть тех, которые не связаны напрямую с продуктом, то лучше их либо делить на 12, либо уже включать только в годовую отчетность

если подписочная модель, то тогда записывать не всю оплату в один месяц, а растягивать на весь срок подписки, чтобы не забирать деньги у себя в будушем

• Что является юнитом?
- минимальная сущность, на которой можно посчитать маржу, доходы, расходы

• Как учитывать прямые и косвенные расходы?
- прямые учитываем в экономике продукта, косвенные только в отчетности, но не в юнит экономике

• Как считать LTV и отток, почему нельзя использовать фиксированное окно?
LTV считаем как (arpu*валовая маржа)/churn
отток = 1-retention

фиксированное окно использоватьт нельзя, потому что retention меняется, также по когортам ltv меняется

</details>


<details>
  <summary>Lofty</summary>
  пт

# [1] SQL

 ```sql
-- Требуется: написать SQL‑запрос, который вернёт всех пользователей из таблицы users, которые никогда не оставляли комментарии (то есть их user_id не встречается в таблице comments)

select user_id
from users left join comments using (user_id)
where comment_id is null
 ```

 # [2] Статистика и A/B‑тесты

 1) Задача 1. Тест для метрики‑отношения (конверсии)

 Компания проводит A/B‑тест, целевая метрика — конверсия (отношение количества целевых действий к числу пользователей или показов). Нужно:

описать, какой статистический тест уместно использовать для сравнения конверсий между группами;

z-тест для пропорций, t-тест применим только при линеаризации

объяснить, зачем применяется техника линеаризации и как её использовать вместе с выбранным тестом.
линерализация - техника преобразования метрики, которая уменьшает дисперсию и позволяет использовать t-тест



2) Задача 2. Интерпретация p‑value

Объясните, что такое p‑value в контексте A/B‑тестирования и проверки гипотез:

как его правильно интерпретировать;

p - value - вероятность получить такое или более экстремальное значение при условии, что нулевая гипотеза верна
если p-value < a, то тогда мы отклоняем нулевую гипотезу и после построения дов интервала понимаем, есть ли полезный эффект от фичи

как оно связано с уровнем значимости α и ошибкой первого рода;

мы сравниваем p-value с уровнем значимости и принимаем решение на основе этого - по сути чем больше ошибка первого рода (альфа), тем чаще p-value будет отклонять гипотезу

какое решение мы принимаем в зависимости от величины p‑value.

есть ли стат значимый эффект или нет - катим фичу или нет



3) Задача 3. Стратификация в A/B‑тестах
Нужно:

объяснить, что такое стратификация в A/B‑тестировании;

- это разбиение трафика на однородные группы (страты) перед рандомизацией, чтобы внутри каждой группы пропорции АБ были одинаковыми 

как формируются страты и по каким признакам это можно делать;

- устройство, гео, новый/старый пользователь, канал трафика 


каким образом стратификация влияет на дисперсию оценок и точность результатов теста.

- она уменьшает ошибку первого и второго рода, поскольку мы можем либо задетектить эффект, где его нет, либо наоборот не увидеть, поскольку какая-то группа будет оказывать больше воздействия - и тогда не соблюдется условие случайного распределения пользователей

(то есть уменьшает дисперсия оценки эффекта)


4) Задача 4. Проверки перед запуском A/B‑теста
Перед запуском A/B‑теста команда хочет убедиться, что тест корректно задизайнен и будет давать достоверные результаты. Опишите:

какие проверки и sanity‑чекы нужно сделать до старта теста (или на этапе A/A‑теста);

- сначала прогоняем хэщ-функцию на большом кол-во юзеров (то есть симулируем распределение)
- потом проверяем равномерность распределения (кол-во в каждой группе, разбиение по сегментам)
- попадает ли пользователь всегда в одну и ту же группу
- провести а/а тест и проверить, не выдает ли наша метрика p-value ниже альфы
- можно с помощью монте-карло просимулировать аа-тест (чтобы проверить корректную работу критерия - точно ли у нас получится уровень значимости a), также можес просимулирвоать аб тест на исторических данных, чтобы сравнить тесты и понять, у какого мощность выше

какие распределения и метрики стоит сравнить между группами; 

- распределение по сегментам (гео, новый/старый, пол, возраст, канал трафика)
- конверсию в целевое действие, arpu, размеры сессий и тд

что является «хорошим» результатом таких проверок;

- что p-value>0.05 в аа тесте
- распределение по сегментам примерно одинаковое
- кол-во пользователей в каждой группе одинаково

какие выводы можно сделать, если обнаружены сильные перекосы между группами.

- что хэш-функция работает некорректно, возможно стоит применить стратификацию
- тест запускать нельзя


5) Задача 5. Оценка эффекта без A/B‑теста
Фича уже целиком выкатана на продакшен, провести классический A/B‑тест невозможно. При этом нужно оценить её влияние на ключевые метрики продукта.

Вопрос: какие подходы можно использовать для оценки эффекта в такой ситуации (до/после, квази‑эксперименты и т.п.), и какие ограничения у этих подходов?

- casual inference (нужно много признаков для корректного моделирования)
- diff and diff (не всегда можно найти схожие группы пользователей, эффект фичи может смешиваться с другими эффектами, нужен тест и контроль)
- временные ряды (нельзя отделить эффект фичи от других изменений в продукте или сезонности)

 # [3] Python / Pandas

 Задача 1. Объединение двух DataFrame

Имеются два объекта pandas.DataFrame, в обоих содержится общий ключевой столбец user_id. Опишите, как в Pandas можно:

выполнить объединение по ключу (аналог SQL JOIN);

- merge

какие виды соединений поддерживаются (left, right, inner, outer);

left, right, inner, outer

какими методами библиотеки pandas это реализуется.

df.merge (df1, on = '', how = '')


Задача 2. Фильтрация по дате
Дан DataFrame df с колонкой event_date в формате даты. Нужно отфильтровать строки только за одну конкретную дату, например '2024-01-01'.

```python
df = df[df['event_date'] == '2024-01-01']
```
Опишите, как это сделать с помощью булевой индексации и/или методов .loc в Pandas.

```python
df = df.loc[df['event_date'] == '2024-01-01']
```
# [4] Продуктовые и бизнес‑кейсы

# [4.1] Кейс 1. Сравнение CPC и CPM‑кампаний при выборе победителя аукциона

RTB‑платформа одновременно обслуживает рекламные кампании двух типов:

CPC — рекламодатель платит только за клики;
CPM — рекламодатель платит за показы (за 1000 показов).
Во время аукциона для одного рекламного слота одновременно есть несколько кандидатов‑баннеров с разными ставками и разным типом оплаты. Для каждого баннера есть исторические данные и/или предсказанная вероятность клика (CTR).

Требуется: предложить, как сравнивать между собой ставку за показ (CPM) и ставку за клик (CPC), чтобы выбрать для показа наиболее выгодный для платформы баннер. Какие метрики или ожидаемые величины дохода нужно считать и по какой формуле?

1) Что нам вообще нужно сделать?

Нам нужно заработать как можно больше денег, выбрав правильный баннер (то есть разница прибыли и затрат должна быть максимальной). Для платформы чем лучше алгоритм, тем больше прибыли от баннера как платформе, так и рекламодателю. И к тому же, нам нужно сделать так, чтобы мы не потратили бюджет рекламодателя впустую


2) Определеяем ожидаемый доход с каждой ставки

CPCод = CPCставка * 1000 показов * CTR (чтобы сделать эквивалентным CPM)
CPMод = CPMставка (доход уже за 1000 показов)

3) Сравниваем баннеры:
Выбираем CPCставка * 1000 показов * CTR  или CPMставка (что больше - то и выбираем)

# [4.2] Кейс 2. Сегментация рекламодателей

Задача: провести сегментацию рекламодателей платформы. В вашем распоряжении есть данные о каждом показе и клике, в том числе:

идентификатор рекламодателя;
баннер и формат;
стоимость показа/клика;
частота показов и кликов;
общий бюджет и траты рекламодателя в платформе;
дополнительные поведенческие метрики.
Вопросы:

какие признаки (фичи) вы бы использовали для сегментации рекламодателей;

если более классически, то разбила бы работодателей по:
- сумме ставок (низкорискованые, среднерискованые и высокорискованные) - признак стоимость показа/клика
- и также по платежеспособности работодателя (общий бюджет и траты рекламодателя в платформе)
- по форматам (классификаиция)
- по частота показов и кликов

если с использованием ML, то можно сделать классификацию (kmeans, например) и посмотреть shap - то есть какие признаки на какой кластер повлияли - здась уже получатся новые интересные зависимости

какие типы сегментов можно построить (по бюджету, качеству трафика, стабильности, вовлечённости и т.п.);

- написала выше

какие практические действия можно предпринять для разных сегментов (условия, офферы, приоритизация поддержки и т.д.).

- крупные рекламодатели - персональный менеджер, скидки за объём, приоритизация поддержки
- малые рекламодатели - образовательные материалы, рекомендации по оптимизации
- высокая вовлеченность - предложить новые форматы, бета-функции, апселл
- низкая вовлеченность - уведомления о промо, автоматизированные офферы

</details>

<details>
  <summary>Pari Дофига кейсов</summary>
  сб

# [1] Парадокс Симпсона и ARPU по регионам

> Условие. Есть коммерческая компания, работающая в разных регионах России. Все регионы делят на два кластера:
> Кластер A: Москва + Санкт-Петербург.
> Кластер B: все остальные регионы.
> Год к году средний ARPU вырос в кластере A и вырос в кластере B. Однако по всей стране в целом (A + B) ARPU год к году снизился.

Вопросы:

**Может ли такая ситуация быть в реальности? Если да — почему?**

Да, может, об этом говорит парадокс Сипмсона. Например, изменились размеры кластеров, а соответственно и их веса в общей формуле. Изменение в структуре выборки могло перебить рост внутри кластера

**Приведи интуитивное объяснение (без формул) и конкретный пример, в чём здесь «подвох».**

Например, в кластере А ARPU высокий, в кластере В низкий. Если резко увеличивается доля в В (при том, что рост ARPU вырос, но остается ниже, чем в А), то вклад дешевого сегмента будет увеличиваться сильнее, чем рост арпу

Конкретный пример

2024
Кластер А: 1000
Кластер В: 200
Средний арпу: 1000 * 0.1 + 200 * 0.9 = 280
Доля жителей: кластер А - 10%, кластер В - 90%

2025
Кластер А: 1100
Кластер В: 250
Средний арпу: 1100 * 0.03 + 250 * 0.97 = 275.5
Доля жителей: кластер А - 3%, кластер В - 97%

В каждом кластере арпу вырос, а средний упал

**Как бы ты проверял подобные эффекты в реальных данных, чтобы не попасть в ловушку агрегации?**

* Нужно смотреть не только метрику в общем, но и по сегментам, нельзя делать однозначный вывод о конкретном сегменте, опираясь на данные за все сегменты
* Пересчитать арп за текущий год со структурой прошлого

# [2] Новый алгоритм поиска в e-commerce: дизайн A/B-теста

> Условие. В интернет-магазине есть текущий алгоритм поиска (baseline) и новый алгоритм.
> По offline-метрике (оценка релевантности асессорами) новый алгоритм работает лучше baseline.
> Нужно понять, даёт ли новый поиск реальный прирост в деньгах и пользовательских метриках online.

Вопросы:

**Как ты задизайнишь online A/B-тест для проверки нового поиска?**

Поскольку здесь фича уже раскатана, то мы не можем применить стандартный т тест, для этого мы можем использовать
- козал инференс (моделируем на исторических данных, как бы выглядели метрики, если бы фича не была раскатана и сравниваем с тем, как ведут себя метрики в реальности)
- див ин диф (сравниваем с метриками или с группой, с которой есть корреляция - нсколько изменилась разница в метриках?)
- временной ряд (моделируем только одну метрику и сравниваем есть ли разница с реальностью)

Но будем считать что фича не раскатана на всех, а мы только планируем это делать, поэтому будет проверять гипотезу о равенстве средних через т-тест

H0: мат ожидания равны
Н1: мат ожидание нового алгоритма выше

Метрики: 
Целевые:
CTR (из поиска в первые три карточки)
CTR (из веедния запроса в добавление в корзину)
Revenue per search
Search conversion rate

Заградительные:
% churn (кто зашел, ввел запрос и ушел)

Информационные:
Скорость алгоритма


поскольку это ratio метрика, то нам нельзя использовать т тест, поэтому используем бусттрап/линеаризацию

**На что смотреть, чтобы не «каннибализировать» другие зоны сайта (главная, рекомендации и т.п.)?**

Можно смотреть на CTR в рекомендательных блоках и на главной, изменение распределения заходов на страницы поиска и другие 

- Как ты будешь считать объём выборки: какую MDE возьмёшь, какие значения α и β (мощность) заложишь, и как изменение мощности (80% → 90%) повлияет на требуемый размер выборки?

a - 5%
b - 80% (по стандарту)

MDE посчитаю из юнит экономмики и параметров теста
объём выборки посчитаю через ноутбук по функции из расчета MDE, a, b, дисперсии
увеличение мощности повлияет на больший размер выборки

# [3] Денежные метрики: t-test, распределения и снижение дисперсии

> Условие. В A/B-тестах используются денежные метрики:

>ARPU (средний доход на пользователя).
>Средний чек.
>Количество заказов на пользователя.


**1 - Какими статистическими тестами ты бы проверял значимость разницы по этим метрикам в A/B-тесте?**

ARPU - использовать уровень пользователя (то есть распределение состоит из общей суммы ставок на 1 пользователя), использовать Welch’s t-test (модификация т-теста, не требует равенства дисперсий)
AOV - бутстрап/ленеаризация + t-test
Количество заказов на пользователя - т - тест на уровне пользователя / модель отрицательной биномиальной регрессии
**2 - Почему наивный t-test может плохо работать для ratio-метрик (например, среднего чека) и тяжёлых хвостов распределения выручки?**

Потому что и при ARPU, и при AOV мы получаем сильно скошенные распределения, поскольку в ratio метриках зависимость числителя и знаменателя приводит к сложной дисперсии, поэтому при малых заказах метрика сильно гуляет. С тяжелыми хвостами т-тест может справляться, поскольку т-тест чувствителен к сильным выбросам

**Как выглядит распределение ARPU в реальном продукте и какие проблемы оно создаёт для тестов?**

Это экспоненциальное распределение, большинство значений сосредоточено в левой части графика. Для тестов может создавать проблему в том, что довольно большая дисперсия, поэтому тест длится дольше, чтобы набрать достаточную выборку

**Какие подходы к снижению дисперсии ты знаешь и как их применил бы здесь (CUPED / ковыриаты, стратификация / пост-стратификация, обрезка/винсоризация хвостов и т.п.)?**

1) CUPED - выбираем коррелирующую метрику, проводим тест, строим линейную регрессию/линеаризацию (для ratio) и получаем очищенные значения метрик (то есть CUPED убирает шум)

2) Ковариаты - берем уже несколько коррелирующих метрик и строим регрессию с несколькими параметрами

3) Стратификация - сначала делим пользователей на группы, а потом внутри каждой группы случайно делим на а и б (используется для сильно различающихся групп)

4) Пост-стратификация - делаем так уже после проведения теста

5) Винсоризация - когда мы обезаем выбросы (например, по 2,5% с каждой стороны)

В каких случаях CUPED и подобные методы будут работать плохо или почти не дадут выигрыша?

Когда CUPED и подобные методы плохо работают:

Метрика мало коррелирует с предтестовыми данными → эффект минимален
Очень шумные или редкие события (например, покупки у небольшой доли пользователей)
Если ковариата не отражает вариацию текущей метрики

**Что делать с heavy users / «китами», которые могут сильно «ломать» денежные метрики и результаты теста?**

Можем их исключить их теста и проводить только на бОльшей части пользователей или винзоризация


# [4] Два изменения в пуш-рассылке: как разделить эффекты?

> Условие. В букмекерской компании запустили CRM-рассылку:

> В тексте пуша/сообщения изменили формулировку (коммуникацию).
> Одновременно изменили размер фрибета (сам оффер).
> Рассылку уже отправили, но теперь бизнес хочет понять: отдельный эффект текста и отдельный эффект изменения фрибета.

**1 - Как бы ты перезадизайнил эксперимент, чтобы разделить влияние текста и оффера?**

Можно разделить пользователей на 4 группы:
A - те, кто получат старый пуш
В - те, кто получат пуш с новой коммуникацией
С - те, кто получат пуш с новым оффером
D - те, кто получат пуш и с новым оффером, и с новой коммуникацией

Также нужно использовать поправку Бонферрони, чтобы протестировать сразу несколько гипотез

**Какой дизайн теста выбрал бы?**

факторный дизайн с несколькими группами

**Как учитывать проблему множественных проверок и контролировать общий уровень ошибок (подходы типа Bonferroni, Holm и др.)?**

Поправка Бонферрони или Холма

**Какие целевые метрики смотришь (открытие, переход, депозит/ставка, ARPU, отписки и т.д.)?**

Целевые:
CTR в открытие
CTR в выполнение целевого действия

Заградительные:
% тех, кто отключил уведомления после получения пуша
ARPU

# [5] Инкрементальный эффект продукта «боевой пропуск» (battle pass)

> Условие. В продукте есть «боевой пропуск»/прогресс-бар:

> Игроки выполняют игровые и ставочные задания, получают внутреннюю валюту и награды (фрибеты, скины и т.п.).
> Есть дополнительные расходы бизнеса на эти награды и на разработку.
> Классический A/B-тест на включение/выключение этого продукта запустить нельзя.

**1 - Как оценить инкрементальный эффект этого продукта в деньгах?**

- Did - сравниваем изменение выручки у тех, кто включил battle pass, а кто нет

**2 - Как бы ты строил тест/квази-эксперимент: какие группы использовать, как подбирать «двойников», по каким признакам матчить игроков?**

Для матчирования можно взять:
- исторический ARPU
- частота ставок
- типы ставок
- устройство, страна, канал привлечения
- ретеншн

test - те, кто включил battle
control - двойники, которые не включили

Методы матчирования:
- Логистическая регрессия
- propensity score matching

**3 - Как проверять, что до запуска/включения боевого пропуска тестовая и контрольная группы действительно сопоставимы по ключевым метрикам (например, депозиты, выручка, активность)?**

Можно посмотреть на временные ряды метрик - насколько у них коррелируют спады/падения? ну и на исторических данных посмотреть корреляцию
также можно проверить стат значимость по сопоставимым метрикам (например, по т-тесту и хи-квадрату)

**4 - Какой горизонт эффекта и какие метрики (ARPU, частота ставок, удержание) ты бы анализировал?**

Я бы взяла горизонт в минимум 2 недели, чтобы учитывать сезонность, но и учитывала бы срок battle . Смотрела бы ARPU uplift, частота ставок, Retention

# [6] Прогноз продаж и отклонение факта: кейс Ламоды

>Условие. Есть прогноз продаж крупного интернет-ритейлера (пример: Lamoda):
>Модель учитывает тренд, сезонность и какие-то внешние факторы.
>В одном из месяцев (октябрь) факт оказался на ~15% ниже прогноза.

**1 - Как понять, является ли такое отклонение аномальным с точки зрения модели (доверительный интервал прогноза)?**

- построить Prediction Interval (PI) и проверить находятся ли эти 15% внутри него

**2 - Как ты будешь искать причины отклонения: по каким разрезам и факторам пойдёшь?**

- посмотрю на исторические данные
- посмотрю по когортам - может, выручка где-то в одном месте подскочила
(категории товаров, регионы, тип устройств, каналы привлечения)
- посмотреть воронку - может, где-то конкретно падение?
- посмотреть метрики по доставке - может, тут что-то пошло не так?

**3 - На какие внутренние (цены, промо, ассортимент, технические проблемы) и внешние факторы (погода, конкуренты) посмотришь?**

внутренние:
- поломки в данных
- отключили рекламный канал/урезали бюджет
- запустили новый продукт/линий/монетизацию
- техбаги
- out of stock
- изменения в приложении, новый функционал, дизайн

внешние:
- экономическая ситуация (было ли что-то особенное в октябре?)
- конкуренты (может, перешли к конкурентам)
- аномалии в погоде (например6 аномально теплая погода или наоборот заморозки)

Как по результатам анализа скорректировать модель/процесс прогнозирования?

- если это аномалия, то добавить anomaly flag и не включать месяц в обучение
- если нет, то добавить новые признаки и обновить модель

# [7] Общий инкрементальный эффект CRM-коммуникаций

> Условие. В компании много CRM-каналов и активностей:
> Пуш-уведомления, SMS, email-рассылки.
> Коммуникации с матчами, промо, персональными офферами и т.п.
> Команда видит по операционным метрикам, что какие-то кампании «стреляют», у каких-то высокие открытия и клики, но нет понятного ответа: сколько в целом денег приносит направление CRM инкрементально.

**1 - Как оценить общий инкрементальный эффект CRM-коммуникаций, а не только «последний клик» от конкретного пуша?**

- временно отключить некоторые каналы и посмотреть, что изменилось (сильно ли снизилась выручка?)
- посмотреть корреляцию кол-ва взаимодействий с пользователями и выручкой по дням 

**2 - Как можно использовать глобальные контрольные группы (часть базы, которую на время вообще не трогаем коммуникациями) для оценки эффекта?**

мы можем в тестовую группу определить тех, кто не будет получать коммуникацию, а в качестве контрольной взять тех, кто получает коммуникацию

**3 - Какие риски и ограничения есть у такого подхода и как их минимизировать (выбор размера и состава контроля, длительность эксперимента, этика/бизнес-риски и т.п.)?**

риски и ограничения:
- потеря выручки (для минимизации можно отключать каналы постепенно, начать с того, который по прогнозам приносит меньше всего прибыли)
- часть пользователей отвалится, потому что не будет получать коммуникацию, то есть мы можем понизить ретеншн (не отключать критически важные коммуникации)

**4 - Какие метрики на горизонте эксперимента ты бы анализировал (выручка, депозиты, удержание, LTV, отписки, усталость от коммуникаций)?**

- Revenue per channel
- LTV
- Retention
- Отписки

</details>

<details>
  <summary>AliExpress</summary>
вс

# [1] Задача

 ```sql
select t1.fullname, t1.salary, t2.fullname
from employees t1 join employees t2 on t1.managerid = t2.id and t1.salary > t2.salary
 ```

 # [2] Задача

 ```sql
with tmp as (select user_id, order_dt,
sum(gmv) over (partition by user_id order by order_dt) as sm
from orders
where extract (year from order_dt) = 2025),

  tmp_2 as (select user_id, order_dt, sm,
row_number() over (partition by user_id order by order_dt) as rn
from tmp
where sm >= 10000)

select user_id, order_dt
from tmp_2
where rn = 1
 ```

# [3] Задача

 ```sql
with tmp as (
  select user_id, name, count(order_id) as cnt
  from users u join orders o on u.user_id = o.user_id 
  where o.status = 'done'
  group by user_id, name
)
select name 
from tmp
where cnt >= (select percentile_cont(0.95) within group (order by cnt) from tmp)
 ```

 # [4] Задача

 ```python
 def func(nums, target):
  final = []
  nums.sort()
  for i in range (len(nums)):
    if nums[i] == target:
      final.append(i)
  
  if final == []:
    return [-1, -1]
  else:
    return [final[0], final[len(final)-1]]
 ```
</details>

<details>
  <summary>Tripster</summary>
пн

# [1] Задача SQL

 ```sql
with tmp as (select user_id, 
min (case when event_time = 'install' then event_time ens) as first_install,
min (case when event_time = 'purchase' then event_time ens) as first_purchase
from events
group by user_id)

select user_id, DATEDIFF ('dd', first_install, first_purchase) as day_diff,
revenue
from tmp t1 join events t2 
on t1.user_id = t2.user_id 
and t1.first_purchase = t2.event_time
and t2.event_type = 'purchase'
 ```

# [2] Задача SQL

 ```sql

with tmp as (select user_id, event_time, 
count(*) over (partition by user_id) as cnt_pur,
lag(event_time) over (partition by user_id order by event_time) as lg_pur
from events
where event_type = 'purchase')

tmp_2 as (
select user_id, max(datediff ('dd', lg_pur, event_time)) as max_gap_days
from tmp
where cnt_pur >= 3
group by user_id)

select user_id,
case
when max_gap_days > 30 then True else False
end as churned
from tmp_2
 ```

# [3] Python - Построение таблицы ретеншена пользователей по дням

 ```python
'''1 - Сначала найдем когорты'''
install_days = df[df['event_type'] == 'install'][['user_id', 'event_date']].rename(columns = {'event_date':'install_date'})

'''2 - Теперь отделим сессии пользователей'''
sessions = df[df['event_type'] == 'session'][['user_id', 'event_date']].rename(columns = {'event_date':'session_date'})

'''3 - Соединяем сессии и дни установки, чтобы посчитать разницу между сессией и установкой для каждого пользователя'''
sessions = sessions.merge(install_days, on = 'user_id')
sessions['diff'] = (sessions['session_date'] - sessions['install_date']).dt.days.rename('diff')

'''4 - Теперь посчитаем, сколько уникальных пользователей в каждой когорте и разнице'''
sessions = sessions.groupby(['install_date', 'diff'])['user_id'].nunique().rename('count_users').reset_index()

'''5 - Теперь сделаем разницу столбцами'''
retention = sessions.pivot(index = 'install_date', columns = 'diff', values = 'count_users')
retention.columns = [f"day_{c}" for c in retention.columns]

'''6 - Получили матрицу ретеншна, теперь сделаем доли'''
cohort_size = install_days.groupby('install_date')['user_id'].nunique().rename('count_cohort')
retention = retention.divide(cohort_size, axis = 0).round(2).fillna(0)
 ```

 # [4] Вопросы по статистике

**Ошибка I рода и ошибка II рода**
1 рода - это вероятность ошибиться ложноположительно, то есть отвергнуть нулевую гипотезу, а она на самом деле верна
2 рода - вероятность ошибиться ложноотрицатльно, то есть принять нулевую гипотезу, а она не верна

**p-value**

это вероятность увидеть такое или более экстремальное значение при условии, что нулевая гипотеза верна

**Доверительный интервал**

это диапазон, который с заданной вероятностью содержит истинное значение

**Перцентили**

это значение, ниже которого находится заданный процент значений

# [5] Кейс 1 — «Баннер и сравнение кликнувших vs некликнувших»

> Контекст:
> У компании есть сайт-маркетплейс. На главной странице был выкатан новый баннер. При клике по баннеру пользователю показывается анимация и сообщение «Вы наш лучший клиент». Больше ничего функционально не меняется.

> Менеджер не запускал A/B-тест, он просто выкатил баннер на всех. После выката он посмотрел метрики: среди пользователей, которые кликнули по баннеру, конверсия в заказ на 50% выше, чем среди пользователей, которые не кликнули по баннеру.

> Менеджер сделал вывод: баннер повышает конверсию → надо поставить его на другие страницы. Он утверждает, что фактически у него получился "псевдо A/B-тест", потому что есть две группы («кликнувшие» и «некликнувшие»), и метрики отличаются значительно и статистически значимо.

**Корректна ли логика менеджера? Можно ли считать, что сравнение кликнувших и некликнувших — это A/B-тест?**

нет, поскольку менеджер упускает наличия третьего фактора - например, что если пользователь активный, то он нажмет на баннер, ну а у активных пользователь конверсия выше. то есть есть некий третий фактор, который коррелирует с другими

ну и для а/б теста была нарушена методология - не был расчет длительности, выборки, MDE, чтобы корректно посчитать стат значимость

**Является ли наблюдаемая разница в конверсии доказательством эффективности баннера?**
**Если нет — почему?**

объяснила выше

**Как нужно было правильно ставить эксперимент?**

сначала нужно было разделить выборку на А и Б, посчитать объём выборки, MDE, установить альфа и бетта, затем выбрать тест (для конверсии - линеаризация + т-тест), потом подождать длительность и далее уже посмотреть на p-value

**Как формировать выборки?**

50/50 - те, кто увидели и не увидели баннер
единица рандомизации - пользователь

**Какие группы нужны?**

**Какие метрики?**

Целевые: 
CTR в целевое действие
ARPU

Заградительные
churn rate

Информационные:
CTR в клики на баннер

**Какие опасности?**

Пользователи, которые увидели этот баннер, могли зачерниться

**Какие данные нужны, чтобы корректно оценить эффект, если A/B-теста не было?**

исторические данные, чтобы проводить casual inference, diff in diff, анализ временных рядов
на этих данных нужно смотреть на корреляции с другими метриками, группами пользователей

# [6] Кейс 2 — «Тип обращения в SMS-рассылках»

>Контекст:
>Компания отправляет пользователям SMS-сообщения. Есть два вида сообщений:

>Тип 1: «Уважаемый клиент»
>Тип 2: «Имя Отчество»
>Фактически уже была проведена отправка сообщений без полноценного A/B-теста:
>Сообщения типа 1 отправили → конверсия 40%
>Сообщения типа 2 отправили → конверсия 45%

>Размеры групп разные:
>Группа 1: 1000 пользователей
>Группа 2: 2000 пользователей

>Менеджеры хотят сделать вывод: Тип 2 лучше, давайте всегда отправлять его.
>Тест был остановлен раньше, чем требовалось. Для MDE = 2% и α = 5% по расчётам требуется 5000+ пользователей в каждой группе, а сейчас в тесте лишь 1000 и 2000.

**Можно ли считать разницу (40% vs 45%) статистически значимой? Что нужно для этого посчитать?**

Нет, потому что нужно смотреть не по процентам, а по p-value/доверительному интервалу

**Достаточно ли объёма выборки?**

Тест некорректный, то есть объёмы выборок разные в разных группах. Тем более по расчету требуется гораздо больше объём, а тест был остановлен раньше

**Как определить, сколько наблюдений надо?**

Нужно посчитать объём в зависимости от MDE, a, мощности, дисперсии

**Что такое MDE?**

Минимально детектируемый эффект, который тест сможет обнаружить при заданном уровне мощности

**Почему с малым количеством данных нельзя делать выводы?**

Потому что при малом объёме выборки высокая случайная вариативность и недостаточная мощность теста, поэтому наблюдаемая разница может быть результатом шума, а не случайного эффекта

**Что делать, если тест был остановлен слишком рано?**

Запускать занаво, либо перезапускать, потому что нельзя делать выводы

**Можно ли использовать группы разного размера?**

Да, группы разного размера допустим, но при сильном дисбалансе снижается стат мощность

**Смущает ли, что группы не 50/50, а 33/67?**

Критично, если SRM

**Нужно ли останавливать тест из-за "слишком большой разницы на первой неделе"?**

Нет, потому что потом всё может выровняться, просто ещё недостаточно наблюдений (peeping problem)

</details>

<details>
  <summary>Гемблинг кейсы</summary>
вт
</details>

<details>
  <summary>?</summary>
ср
</details>

</details>